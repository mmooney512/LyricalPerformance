---
title: "Song Summary"
author: "Michael_M"
date: "Jan 2020"
output:
  html_document: default
  pdf_document: default
  theme: spacelab
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Song Summary

Data wrangling is documented in appendices code listings, clean_rankings.R and match_songs_ranks.R. 

The overall procedure was extracting the lyrics for six artists from the website https://www.azlyrics.com including artist name, album name, year the album was released.  Using the website https://www.billboard.com I extracted what was the peek rank and date of the peek rank for the song on the Billboard Hot 100 chart.  The Billboard Hot 100 will be used as metric to determine the relative success of the song.  While no metric can encapsulate how successful a song that all listeners would agree too, the chart is recognized by the music industry as reliable proxy.  


### Load Library Files

```{r library_files}
library(tibble ,quietly = TRUE, warn.conflicts = FALSE)
library(magrittr ,quietly = TRUE, warn.conflicts = FALSE)
library(dplyr ,quietly = TRUE, warn.conflicts = FALSE)
library(ggplot2 ,quietly = TRUE, warn.conflicts = FALSE)
library(NLP ,quietly = TRUE, warn.conflicts = FALSE)  #used by tm
library(tm ,quietly = TRUE, warn.conflicts = FALSE)

library(knitr ,quietly = TRUE, warn.conflicts = FALSE)

```


## Sample Record

Look at sample record in the data frame

```{r sample_record}

df_songs_lyrics <- readr::read_tsv(file.path(paste0(getwd(), "/df_song_lyrics.txt")))

# ----------------------------------------------------------------------------
# look at one of the values
# ----------------------------------------------------------------------------
glimpse(df_songs_lyrics[255,])
```

### Data Dictionary

album_decade: decade album was released
charted: did the album chart
numberone: was it a number one song
chart_group: was it a top ten, 11-100, or not-charted


## Visualizations

### Charted Songs by Artist

```{r count_metrics ,echo=FALSE}
count_songs <- nrow(df_songs_lyrics)
count_artists <- 6
count_number_one <- sum(df_songs_lyrics$NumberOne)
count_top_ten <- df_songs_lyrics %>% filter(chart_group == "Top 10") %>% nrow()
count_top_100 <- df_songs_lyrics %>% filter(chart_group == "Top 100") %>% nrow()
```

In our data sample there are `r count_songs` songs, by `r count_artists` artists with `r count_top_ten` top 10 songs,
`r count_number_one` being number one songs, 
and `r count_top_100` other songs that were in the top 100.



```{r songs_by_artist_charted}

library(ggplot2 ,quietly = TRUE, warn.conflicts = FALSE)

df_songs_lyrics %>%
  group_by(artist, charted) %>%
  summarise(number_of_songs = n()) %>%
  ggplot() +
  geom_bar(aes(x=artist
               ,y=number_of_songs
               ,fill = charted)
          ,stat = "identity") +
  labs(x=NULL, y="# of Songs")+
  ggtitle("Charted Songs by Artist")

```


### Songs by Artist and Chart Group


```{r songs_by_artist_chart_group}
df_songs_lyrics %>%
  group_by(artist, chart_group) %>%
  filter(peek_rank > 0) %>%
  summarise(number_of_songs = n()) %>%
  ggplot() +
  geom_bar(aes(x=artist
               ,y=number_of_songs
               ,fill = chart_group)
          ,stat = "identity") +
  labs(x=NULL, y="# of Songs") +
  ggtitle("Songs by Artist and Chart Group")

```


### Number 1 Songs by Artist

```{r number1_songs_by_artist}

df_songs_lyrics %>%
  group_by(artist) %>%
  filter(peek_rank == 1) %>%
  summarise(number_of_songs = n()) %>%
  ggplot() +
  geom_bar(aes(x=artist
               ,y=number_of_songs
               ,fill = artist)
          ,stat = "identity") +
  labs(x=NULL, y="# of Songs") +
  ggtitle("Number 1 Songs by Artist and Chart Group")



```




# Lyric Details


```{r library_files_2}
library(tidytext ,quietly = TRUE, warn.conflicts = FALSE)

```

## Prepare the lyrics for analysis

In preparing the lyrics for analysis need to do the following.  
1. Remove any unique words, words in the source document that weren't meant to be part of the lyrics
2. Ensure everything is in lower case
3. Remove any numbers or punctuation that was in the lyrics. The main reason is to remove apostrophes from contraction words,
however it will also remove any commas or periods from the text.
4. Remove stop words from the lyrics
4. Strip any white space around the words.
5. Lastly remove any word that isn't at least three characters in length.

Stop words are common words that we will remove before the text analysis. There is no common universal list of stop words,
and it is subjective as to which stop words to remain and remove.  In addition to the list of stop words listed in the snowball
R package I have included some other words I wanted to remove because I don't think they add value to the analysis. 

```{r prep_lyrics_analysis}

remove_words <- c("chorus", "repeat" ,"hey" ,"uh" ,"whoa"
                 )

scrubLyrics <- function(text_lyric){

  # convert to lower case, remove numbers, punctuation, stopwords, whitespace
  text_lyric <- text_lyric %>%
                  tolower() %>%
                  removeNumbers() %>%
                  removePunctuation() %>%
                  removeWords(stopwords("en")) %>%
                  stripWhitespace()

  return(text_lyric)
    
}

# copy into new dataframe
df_scrubbedLyrics <- df_songs_lyrics

# scrub the lyrics
df_scrubbedLyrics$lyrics <- lapply(df_scrubbedLyrics$lyrics, scrubLyrics)

# tokenize the lyrics
# expand the data frame so one word per row
# remove 
df_scrubbedLyrics <- df_scrubbedLyrics %>%
  tidytext::unnest_tokens(t_words , lyrics) %>%
  filter(!t_words %in% remove_words) %>%
  filter(nchar(t_words) >=3 )


```



## Word Frequency

One of the features of songs we want to explore is, does the number of words in a song impact it's performance?
I will look at the total number of words in the songs to help determine. 

```{r word_frequency}
df_all_words <- df_songs_lyrics %>%
  unnest_tokens(t_words , lyrics) %>%
  group_by(artist, song_title, chart_group) %>%
  summarise(word_count = n()) %>%
  arrange(desc(word_count))


df_all_words %>%
  ggplot() +
  geom_histogram( aes(x=word_count, fill=chart_group)) +
  labs(x="Words per Song", y="# of Songs") +
  ggtitle("Songs by Artist and Chart Group") +
  theme(legend.title = element_blank())

```


Compare the chart groups side by side


```{r Words_per_song_by_group}

df_all_words %>%
  ggplot() +
  geom_histogram( aes(x=word_count, fill=chart_group)) +
  facet_wrap(~chart_group, ncol = 3) +
  labs(x="Words per Song", y="# of Songs") +
  ggtitle("Songs by Artist and Chart Group") +
  theme(legend.title = element_blank())


```



## Most Common Words Used in Lyrics

```{r most_common_words_used_in_lyrics}

df_scrubbedLyrics %>%
  distinct() %>%
  count(t_words, sort = TRUE) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(t_words = reorder(t_words, n)) %>%
  ggplot() +
    geom_col(aes(t_words, n), fill = "#E69F00") + 
    coord_flip() +
    labs(x="Songs per Word", y="# of Songs") +
    ggtitle("Most Frequenty Used Word in Lyrics")

```



```{r most_common_words_used_in_lyrics_by_artist, fig.width=7}

words_by_artist <- df_scrubbedLyrics %>%
  distinct() %>%
  group_by(artist) %>%
  count(t_words, artist, sort = TRUE) %>%
  slice(seq_len(10)) %>%
  ungroup() %>%
  arrange(artist , n) %>%
  mutate(display_row = row_number())

words_by_artist %>%  
    ggplot() +
    geom_col(aes(display_row, n, fill=artist)
             ,show.legend = FALSE) + 
    coord_flip() +
    facet_wrap(~artist, scales = "free") +
    scale_x_continuous(labels = words_by_artist$t_words
                       ,breaks = words_by_artist$display_row) +
    labs(x="Songs per Word", y="# of Songs") +
    ggtitle("Most Frequenty Used Word in Lyrics by Artist") 

```




```{r most_common_words_used_in_lyrics_by_chart_level, fig.width=7}

words_by_chart_group <- df_scrubbedLyrics %>%
  distinct() %>%
  group_by(chart_group) %>%
  count(t_words, chart_group, sort = TRUE) %>%
  slice(seq_len(10)) %>%
  ungroup() %>%
  arrange(chart_group , n) %>%
  mutate(display_row = row_number())

words_by_chart_group %>%  
    ggplot() +
    geom_col(aes(display_row, n, fill=chart_group)
             ,show.legend = FALSE) + 
    coord_flip() +
    facet_wrap(~chart_group, scales = "free") +
    scale_x_continuous(labels = words_by_chart_group$t_words
                       ,breaks = words_by_chart_group$display_row) +
    labs(x="Songs per Word", y="# of Songs") +
    ggtitle("Most Frequenty Used Word in Lyrics by Chart Group") 

```





# ----------------------------------------------------------------------------

# Prediction

# ----------------------------------------------------------------------------


```{r library_files_prediction}
library(tibble ,quietly = TRUE, warn.conflicts = FALSE)
library(magrittr ,quietly = TRUE, warn.conflicts = FALSE)
library(dplyr ,quietly = TRUE, warn.conflicts = FALSE)
library(ggplot2 ,quietly = TRUE, warn.conflicts = FALSE)

```


```{r pivot_table_song_counts}
df_songs_lyrics %>%
  group_by(artist ,chart_group) %>%
  summarise(SongCount = n()) %>%
  reshape2::dcast(artist ~ chart_group, value.var = "SongCount") %>%
  `colnames<-` (c("artist","Not.Charted","Top.10","Top.100")) %>%
  mutate(Total = Top.10 + Top.100 + Not.Charted)

```


How many unique words in each chart group
Word needs to be used in at least three songs.

```{r top_words_per_chart_group}
select_n_words <- 5000
    
df_top_words_per_group <-  df_scrubbedLyrics %>%
      group_by(chart_group) %>%
      mutate(group_word_count = n()) %>%
      group_by(chart_group, t_words) %>%
      mutate(word_count = n()
             ,word_percent = word_count / group_word_count) %>%
      select(t_words, chart_group, group_word_count, word_count, word_percent) %>%
      distinct() %>%
      filter(word_count >= 3) %>%
      arrange(desc(word_percent)) %>%
      top_n(select_n_words)

# remove words that are in more than one group
df_top_words <- df_top_words_per_group %>%
      ungroup() %>%
      group_by(t_words) %>%
      mutate(multi_group = n()) %>%
      filter(multi_group < 2) %>%
      select(chart_group, common_word = t_words)

# create lists of unique words by chart_group
words_not_charted <- lapply(df_top_words[df_top_words$chart_group == "Not Charted",], as.character)
words_top_100 <- lapply(df_top_words[df_top_words$chart_group == "Top 100",], as.character)
words_top_10 <- lapply(df_top_words[df_top_words$chart_group == "Top 10",], as.character)

```








```{r create the test_train_sets}
# 50, 10, 20
library(purrr)
library(tidyr)
set.seed(8020)

test_lyric <- df_songs_lyrics %>%
    mutate(uid = seq(1,length(df_songs_lyrics$album_name))) %>%
    group_by(chart_group) %>%
    nest() %>%
    ungroup() %>%
    mutate(n = c(50,20,10)) %>%
    mutate(samp = map2(data, n, sample_n)) %>%
    select(-data) %>%
    unnest(samp)

train_lyric <- df_songs_lyrics %>%
    mutate(uid = seq(1,length(df_songs_lyrics$album_name))) 

train_lyric <- anti_join(train_lyric, test_lyric, by='uid')

```



```{r lyric_features_function}
# put to lower case, remove punctuation, and stop words
train_lyric$lyrics <- lapply(train_lyric$lyrics, scrubLyrics)
test_lyric$lyrics <- lapply(test_lyric$lyrics, scrubLyrics)

# build into tidy versions of the dataframes
# put into long data set
train_lyric_scrubbed <- train_lyric %>%
    select(-uid) %>%
    tidytext::unnest_tokens(t_words , lyrics)

test_lyric_scrubbed <- test_lyric %>%
    select(-n,-uid) %>%
    tidytext::unnest_tokens(t_words , lyrics)

lyric_features <- function(lyric){
    lf <- lyric %>%
    group_by(song_title) %>%
    mutate(word_frequency = n()
           , lexical_diversity = n_distinct(t_words)
           , lexical_density = lexical_diversity / word_frequency
           , reptition = word_frequency / lexical_diversity
           , song_avg_word_length = mean(nchar(t_words))
           , song_title_words = lengths(gregexpr("[A-z]\\W+",song_title)) +1L
           , song_title_length = nchar(song_title)
           , large_word_count = sum(ifelse((nchar(t_words)>7),1,0))
           , small_word_count = sum(ifelse((nchar(t_words)<3),1,0))
           , top_10_word_count 
              = sum(ifelse(t_words %in% words_top_10$common_word,15,0))
           , top_100_word_count 
              = sum(ifelse(t_words %in% words_top_100$common_word,5,0))
           , uncharted_word_count 
              = sum(ifelse(t_words %in% words_not_charted$common_word,5,0))
           ) %>%
      select(-t_words) %>%
      select(album_name             #1. chr
             , song_title           #2. chr
             , artist               #3. chr
             , peek_date            #4. date
             , charted              #5. chr
             , NumberOne            #6. bool
             , peek_rank            #7. num
             , album_year           #8. num
             , album_decade         #9. num
             , word_frequency       #10. num
             , lexical_diversity    #11. num
             , lexical_density      #12. num
             , reptition            #13. num
             , song_avg_word_length #14. num
             , song_title_words     #15. num
             , song_title_length    #16. num
             , large_word_count     #17. num
             , small_word_count     #18. num
             , top_10_word_count    #19. num
             , top_100_word_count   #20. num
             , uncharted_word_count #21. num
             , chart_group          #22. factor 3 levels
             ) %>%
              
      distinct() %>%
      ungroup()
    
    lf$chart_group <- as.factor(lf$chart_group)
    return(lf)
}

train_data_fe <- lyric_features(train_lyric_scrubbed)
test_data_fe <- lyric_features(test_lyric_scrubbed)

```




```{r load_mlr}
library(mlr ,quietly = TRUE, warn.conflicts = FALSE)

```





## Building the Model

## Normalize the datasets

```{r build_predict_model}
col_nm <-c("word_frequency","lexical_diversity","reptition"
           ,"song_avg_word_length","song_title_words","song_title_length"
           ,"large_word_count","small_word_count","top_10_word_count"
           ,"top_100_word_count","uncharted_word_count"
           )
train_data_nm <- normalizeFeatures(train_data_fe
                                   ,method = "standardize"
                                   ,cols=col_nm
                                   ,range=c(0,1)
                                   ,on.constant = "quiet")
test_data_nm <- normalizeFeatures(test_data_fe
                                   ,method = "standardize"
                                   ,cols=col_nm
                                   ,range=c(0,1)
                                   ,on.constant = "quiet")
```




### Create the Classifiers

```{r select_model_Classifiers}

# will use a variety of models to see if any of the models
# preform better with lyrics 

models = list(
      makeLearner("classif.naiveBayes", id = "Naive Bayes")
      , makeLearner("classif.lda", id = "LDA")
      , makeLearner("classif.ksvm", id = "SVM")
      , makeLearner("classif.knn", id = "KNN")
      , makeLearner("classif.rpart", id = "RPART", predict.type = "prob")
      , makeLearner("classif.randomForest", id = "Random Forest", predict.type = "prob")
      , makeLearner("classif.xgboost", id = "XG Boost", predict.type = "prob")
      , makeLearner("classif.nnet", id = "Neural Net", predict.type = "prob")
)

# use cross fold validation
cfold <- makeResampleDesc("CV" ,iters = 10, stratify = TRUE)

```



```{r build_model_Classifiers}

# make classifiers
exclude_cols = c(1:7)
train_clf <- makeClassifTask(id="Lyrics"
                             , data = train_data_nm[-exclude_cols]
                             , target = "chart_group"
                             )
test_clf <- makeClassifTask(id="Lyrics"
                             , data = test_data_nm[-exclude_cols]
                             , target = "chart_group"
                             )
```





```{r build_train_model}
lyric_train_benchmark <- benchmark(models
                         ,tasks = train_clf
                         ,resamplings = cfold
                         ,measures = list(acc, timetrain) 
                         ,show.info = FALSE
                         )

lyric_train_benchmark

```

### Plot Training Results

```{r plot_train_benchmark}
plotBMRSummary(lyric_train_benchmark)

```

### Confustion Matrix
```{r confusion_train}
predictions_train <- getBMRPredictions(lyric_train_benchmark)
calculateConfusionMatrix(predictions_train$Lyrics$`Random Forest`)$result
```

### Feature Importance
```{r test_the_model}
# feature importance
feature_importance <- generateFilterValuesData(task = train_clf
                                               ,method = c("FSelector_information.gain", "FSelector_chi.squared")
                                               )
plotFilterValues(feature_importance,n.show = 20)
```



## Testing the Model

```{r test_the_model2}

rf_model <- train("classif.randomForest",train_clf)
result_rf <- predict(rf_model, test_clf) 
performance(result_rf, measures = acc)

```


```{r confusion_test}
calculateConfusionMatrix(pred = result_rf)
```




